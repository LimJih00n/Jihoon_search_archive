# ğŸš€ TrueVoice MVP ê°œë°œ ë¡œë“œë§µ

## Executive Summary

3ê°œì›” ë‚´ MVP ì¶œì‹œë¥¼ ëª©í‘œë¡œ í•˜ëŠ” ë‹¨ê³„ë³„ ê°œë°œ ê³„íšì…ë‹ˆë‹¤. í•µì‹¬ ê¸°ëŠ¥ì— ì§‘ì¤‘í•˜ì—¬ ë¹ ë¥´ê²Œ ì‹œì¥ ê²€ì¦ì„ ë°›ê³ , í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ë°˜ë³µ ê°œì„ í•©ë‹ˆë‹¤.

## ğŸ“… Timeline Overview

```mermaid
gantt
    title TrueVoice MVP Development Timeline
    dateFormat  YYYY-MM-DD
    section Phase 1
    í”„ë¡œí† íƒ€ì… ê°œë°œ    :2025-02-01, 30d
    ë°ì´í„° íŒŒì´í”„ë¼ì¸  :2025-02-15, 20d
    section Phase 2
    AI ëª¨ë¸ êµ¬ì¶•       :2025-03-01, 30d
    ì›¹ ëŒ€ì‹œë³´ë“œ        :2025-03-15, 20d
    section Phase 3
    í†µí•© í…ŒìŠ¤íŠ¸        :2025-04-01, 15d
    ë² íƒ€ ëŸ°ì¹­          :2025-04-15, 15d
```

## ğŸ¯ MVP Goals & Success Metrics

### Primary Goals
```yaml
ê¸°ìˆ ì  ëª©í‘œ:
- Perigon API í†µí•© ì™„ë£Œ
- ê¸°ë³¸ AI ëª¨ë¸ êµ¬í˜„
- ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
- ì›¹ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œ:
- 10ê°œ íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´
- 70% ì˜ˆì¸¡ ì •í™•ë„ ë‹¬ì„±
- Product-Market Fit ê²€ì¦
- ì‹ ìš©ë³´ì¦ê¸°ê¸ˆ ëŒ€íšŒ ìš°ìŠ¹

Success Metrics:
- Daily Active Users: 50+
- ì˜ˆì¸¡ ì •í™•ë„: 70%+
- ê³ ê° ë§Œì¡±ë„: 4.0/5.0+
- ì²˜ë¦¬ ì†ë„: <5ì´ˆ
```

## ğŸ”„ Phase 1: Foundation (Month 1)

### Week 1-2: í”„ë¡œì íŠ¸ ì„¤ì • ë° ì¸í”„ë¼

#### ê°œë°œ í™˜ê²½ êµ¬ì¶•
```bash
# í”„ë¡œì íŠ¸ êµ¬ì¡°
truevoice-mvp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/          # FastAPI ì„œë²„
â”‚   â”œâ”€â”€ collectors/   # ë°ì´í„° ìˆ˜ì§‘
â”‚   â”œâ”€â”€ ml/          # AI ëª¨ë¸
â”‚   â””â”€â”€ db/          # ë°ì´í„°ë² ì´ìŠ¤
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ dashboard/   # Next.js ëŒ€ì‹œë³´ë“œ
â”‚   â””â”€â”€ landing/     # ëœë”© í˜ì´ì§€
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/      # Docker ì„¤ì •
â”‚   â””â”€â”€ k8s/         # Kubernetes ì„¤ì •
â””â”€â”€ tests/           # í…ŒìŠ¤íŠ¸ ì½”ë“œ
```

#### ê¸°ìˆ  ìŠ¤íƒ ê²°ì •
```yaml
Backend:
- Python 3.11 + FastAPI
- PostgreSQL + Redis
- Celery + RabbitMQ

Frontend:
- Next.js 14 + TypeScript
- Tailwind CSS + shadcn/ui
- Recharts + D3.js

Infrastructure:
- AWS (EC2, RDS, S3)
- Docker + Kubernetes
- GitHub Actions CI/CD
```

#### íŒ€ êµ¬ì„±
```yaml
ê°œë°œíŒ€ (3ëª…):
- ë°±ì—”ë“œ ê°œë°œì: API, ë°ì´í„° íŒŒì´í”„ë¼ì¸
- AI ì—”ì§€ë‹ˆì–´: ML ëª¨ë¸, NLP
- í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì: ëŒ€ì‹œë³´ë“œ, UX

ì§€ì› (2ëª…):
- í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €: ìš”êµ¬ì‚¬í•­, ìš°ì„ ìˆœìœ„
- ë””ìì´ë„ˆ: UI/UX ë””ìì¸
```

### Week 3-4: ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸

#### Perigon API í†µí•©
```python
# perigon_collector.py
import asyncio
from typing import List, Dict
import aiohttp
from datetime import datetime, timedelta

class PerigonCollector:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.goperigon.com/v1"
        
    async def collect_articles(
        self, 
        keywords: List[str],
        timeframe_hours: int = 24
    ) -> List[Dict]:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ê¸°ì‚¬ ìˆ˜ì§‘
        """
        from_date = (datetime.now() - timedelta(hours=timeframe_hours))
        
        params = {
            "apiKey": self.api_key,
            "q": " OR ".join(keywords),
            "from": from_date.isoformat(),
            "language": "ko",
            "sortBy": "relevance",
            "size": 100
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{self.base_url}/search",
                params=params
            ) as response:
                data = await response.json()
                return data.get("articles", [])
    
    async def analyze_sentiment(self, articles: List[Dict]) -> Dict:
        """
        ìˆ˜ì§‘ëœ ê¸°ì‚¬ ê°ì„± ë¶„ì„
        """
        sentiments = []
        for article in articles:
            # Perigonì˜ ë‚´ì¥ ì„¼í‹°ë¨¼íŠ¸ ì‚¬ìš©
            sentiment = article.get("sentiment", {})
            sentiments.append({
                "title": article["title"],
                "sentiment_score": sentiment.get("score", 0),
                "url": article["url"],
                "published_at": article["pubDate"]
            })
        
        return {
            "total_articles": len(sentiments),
            "average_sentiment": sum(s["sentiment_score"] for s in sentiments) / len(sentiments),
            "articles": sentiments
        }
```

#### ì†Œì…œë¯¸ë””ì–´ í¬ë¡¤ëŸ¬
```python
# social_crawler.py
class SocialMediaCrawler:
    def __init__(self):
        self.platforms = {
            "twitter": TwitterCrawler(),
            "instagram": InstagramCrawler(),
            "youtube": YouTubeCrawler()
        }
    
    async def crawl_mentions(
        self,
        brand: str,
        platforms: List[str] = None
    ) -> Dict:
        """
        ë¸Œëœë“œ ë©˜ì…˜ í¬ë¡¤ë§
        """
        if not platforms:
            platforms = list(self.platforms.keys())
        
        results = {}
        tasks = []
        
        for platform in platforms:
            if platform in self.platforms:
                crawler = self.platforms[platform]
                task = crawler.search(brand)
                tasks.append((platform, task))
        
        for platform, task in tasks:
            try:
                data = await task
                results[platform] = data
            except Exception as e:
                logger.error(f"Error crawling {platform}: {e}")
                results[platform] = []
        
        return results
```

## ğŸ¤– Phase 2: AI Development (Month 2)

### Week 5-6: NLP ëª¨ë¸ êµ¬ì¶•

#### í•œêµ­ì–´ ê°ì„± ë¶„ì„ ëª¨ë¸
```python
# sentiment_analyzer.py
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

class KoreanSentimentAnalyzer:
    def __init__(self):
        self.model_name = "tunib/electra-ko-base-sentiment"
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name
        )
        
    def analyze(self, text: str) -> Dict:
        """
        í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„
        """
        # ì „ì²˜ë¦¬
        text = self._preprocess(text)
        
        # í† í¬ë‚˜ì´ì§•
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        )
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.nn.functional.softmax(
                outputs.logits, 
                dim=-1
            )
            
        # ê²°ê³¼ ë§¤í•‘
        labels = ["negative", "neutral", "positive"]
        scores = predictions[0].tolist()
        
        return {
            "sentiment": labels[scores.index(max(scores))],
            "confidence": max(scores),
            "scores": dict(zip(labels, scores))
        }
    
    def _preprocess(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì€ì–´, ì´ëª¨í‹°ì½˜ ì²˜ë¦¬)
        """
        # ì´ëª¨í‹°ì½˜ â†’ í…ìŠ¤íŠ¸ ë³€í™˜
        text = text.replace("ã…‹ã…‹", "ì›ƒìŒ")
        text = text.replace("ã… ã… ", "ìŠ¬í””")
        
        # ì€ì–´ ì •ê·œí™”
        slang_dict = {
            "ã„¹ã…‡": "ì§„ì§œ",
            "ã…‡ã…ˆ": "ì¸ì •",
            "ã„±ã……": "ê°ì‚¬"
        }
        
        for slang, normal in slang_dict.items():
            text = text.replace(slang, normal)
            
        return text
```

#### ì‹ ë¢°ë„ í‰ê°€ ëª¨ë¸
```python
# credibility_scorer.py
class CredibilityScorer:
    def __init__(self):
        self.bot_patterns = self._load_bot_patterns()
        self.authentic_signals = self._load_authentic_signals()
        
    def calculate_score(self, post: Dict) -> float:
        """
        í¬ìŠ¤íŠ¸ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0-100)
        """
        score = 50  # ê¸°ë³¸ ì ìˆ˜
        
        # ë´‡ ì‹ í˜¸ ì²´í¬ (-ì ìˆ˜)
        if self._is_bot_like(post):
            score -= 30
            
        # ê³„ì • ë‚˜ì´ (+ì ìˆ˜)
        account_age_days = self._get_account_age(post)
        if account_age_days > 365:
            score += 15
        elif account_age_days < 30:
            score -= 10
            
        # íŒ”ë¡œì›Œ/íŒ”ë¡œì‰ ë¹„ìœ¨
        ratio = post.get("followers", 0) / max(post.get("following", 1), 1)
        if ratio > 2:
            score += 10
        elif ratio < 0.5:
            score -= 15
            
        # ê°œì¸ ê²½í—˜ ì–¸ê¸‰
        if self._has_personal_experience(post["text"]):
            score += 20
            
        # ê·¹ë‹¨ì  ì–¸ì–´
        if self._has_extreme_language(post["text"]):
            score -= 20
            
        # ë¯¸ë””ì–´ í¬í•¨
        if post.get("has_media"):
            score += 10
            
        return max(0, min(100, score))
    
    def _is_bot_like(self, post: Dict) -> bool:
        """
        ë´‡ íŒ¨í„´ ê°ì§€
        """
        indicators = [
            post.get("username", "").isdigit(),  # ìˆ«ìë¡œë§Œ ëœ ì´ë¦„
            len(post.get("bio", "")) == 0,       # ë¹ˆ í”„ë¡œí•„
            post.get("posts_count", 0) > 10000,  # ê³¼ë„í•œ í¬ìŠ¤íŒ…
        ]
        return sum(indicators) >= 2
```

### Week 7-8: ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ

#### ì‹¤ì œ ë°˜ì‘ ì˜ˆì¸¡ ëª¨ë¸
```python
# prediction_model.py
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import joblib

class RealWorldPredictor:
    def __init__(self):
        self.model = self._load_or_train_model()
        self.feature_names = [
            "online_sentiment",
            "credibility_avg",
            "volume",
            "velocity",
            "platform_diversity",
            "influencer_ratio"
        ]
        
    def predict(self, online_data: Dict) -> Dict:
        """
        ì˜¨ë¼ì¸ ë°ì´í„° â†’ ì‹¤ì œ ë°˜ì‘ ì˜ˆì¸¡
        """
        # íŠ¹ì§• ì¶”ì¶œ
        features = self._extract_features(online_data)
        
        # ì˜ˆì¸¡
        prediction = self.model.predict([features])[0]
        
        # ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        predictions = []
        for tree in self.model.estimators_:
            predictions.append(tree.predict([features])[0])
        
        confidence_interval = np.percentile(predictions, [25, 75])
        
        return {
            "predicted_purchase_intent": prediction,
            "confidence_interval": confidence_interval,
            "confidence_score": self._calculate_confidence(predictions),
            "key_drivers": self._identify_key_drivers(features)
        }
    
    def _extract_features(self, data: Dict) -> List[float]:
        """
        ì˜ˆì¸¡ íŠ¹ì§• ì¶”ì¶œ
        """
        features = []
        
        # ì˜¨ë¼ì¸ ê°ì„± ì ìˆ˜
        sentiments = [p["sentiment"] for p in data["posts"]]
        features.append(np.mean(sentiments))
        
        # í‰ê·  ì‹ ë¢°ë„
        credibilities = [p["credibility"] for p in data["posts"]]
        features.append(np.mean(credibilities))
        
        # ë³¼ë¥¨ (ë©˜ì…˜ ìˆ˜)
        features.append(len(data["posts"]))
        
        # ì†ë„ (ì‹œê°„ë‹¹ ë©˜ì…˜)
        features.append(data.get("mentions_per_hour", 0))
        
        # í”Œë«í¼ ë‹¤ì–‘ì„±
        platforms = set(p["platform"] for p in data["posts"])
        features.append(len(platforms))
        
        # ì¸í”Œë£¨ì–¸ì„œ ë¹„ìœ¨
        influencer_posts = [
            p for p in data["posts"] 
            if p.get("followers", 0) > 10000
        ]
        features.append(len(influencer_posts) / max(len(data["posts"]), 1))
        
        return features
```

## ğŸ’» Phase 3: Frontend Development (Month 2-3)

### Week 7-8: ëŒ€ì‹œë³´ë“œ ê°œë°œ

#### ë©”ì¸ ëŒ€ì‹œë³´ë“œ
```typescript
// dashboard/page.tsx
import React from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip } from 'recharts';

export default function Dashboard() {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    fetchDashboardData();
  }, []);
  
  const fetchDashboardData = async () => {
    try {
      const response = await fetch('/api/dashboard');
      const data = await response.json();
      setData(data);
    } finally {
      setLoading(false);
    }
  };
  
  if (loading) return <LoadingSpinner />;
  
  return (
    <div className="p-6 space-y-6">
      {/* í•µì‹¬ ì§€í‘œ ì¹´ë“œ */}
      <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
        <MetricCard
          title="ì‹¤ì œ ë°˜ì‘ ì˜ˆì¸¡"
          value={data.prediction.score}
          change={data.prediction.change}
          unit="%"
        />
        <MetricCard
          title="ì˜¨ë¼ì¸ ê°ì„±"
          value={data.sentiment.score}
          change={data.sentiment.change}
          unit="ì "
        />
        <MetricCard
          title="ì‹ ë¢°ë„ ì ìˆ˜"
          value={data.credibility.score}
          change={data.credibility.change}
          unit="%"
        />
        <MetricCard
          title="ë°”ì´ëŸ´ ì ì¬ë ¥"
          value={data.viral.score}
          change={data.viral.change}
          unit="%"
        />
      </div>
      
      {/* ì‹¤ì‹œê°„ ì°¨íŠ¸ */}
      <Card>
        <CardHeader>
          <CardTitle>ì˜¨ë¼ì¸ vs ì‹¤ì œ ë°˜ì‘ ë¹„êµ</CardTitle>
        </CardHeader>
        <CardContent>
          <LineChart width={800} height={400} data={data.timeline}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey="time" />
            <YAxis />
            <Tooltip />
            <Line 
              type="monotone" 
              dataKey="online" 
              stroke="#8884d8" 
              name="ì˜¨ë¼ì¸ ì—¬ë¡ "
            />
            <Line 
              type="monotone" 
              dataKey="predicted" 
              stroke="#82ca9d" 
              name="ì˜ˆì¸¡ ì‹¤ì œ ë°˜ì‘"
            />
          </LineChart>
        </CardContent>
      </Card>
      
      {/* ë°ˆ/íŠ¸ë Œë“œ ë¶„ì„ */}
      <MemeAnalysisSection data={data.memes} />
      
      {/* ìœ„í—˜ ì‹ í˜¸ ì•Œë¦¼ */}
      <RiskAlertsSection alerts={data.alerts} />
    </div>
  );
}
```

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```typescript
// components/RealTimeMonitor.tsx
import { useWebSocket } from '@/hooks/useWebSocket';

export function RealTimeMonitor({ campaignId }: { campaignId: string }) {
  const { data, isConnected } = useWebSocket(
    `wss://api.truevoice.ai/ws/${campaignId}`
  );
  
  return (
    <div className="relative">
      <div className="absolute top-2 right-2">
        <StatusIndicator connected={isConnected} />
      </div>
      
      <div className="space-y-4">
        {/* ì‹¤ì‹œê°„ ë©˜ì…˜ í”¼ë“œ */}
        <Card>
          <CardHeader>
            <CardTitle>ì‹¤ì‹œê°„ ë©˜ì…˜</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="space-y-2 max-h-96 overflow-y-auto">
              {data?.mentions?.map((mention) => (
                <MentionCard key={mention.id} mention={mention} />
              ))}
            </div>
          </CardContent>
        </Card>
        
        {/* ì‹¤ì‹œê°„ ê°ì„± ê²Œì´ì§€ */}
        <SentimentGauge value={data?.sentiment} />
        
        {/* íŠ¸ë Œë”© í‚¤ì›Œë“œ */}
        <TrendingKeywords keywords={data?.trending} />
      </div>
    </div>
  );
}
```

## ğŸ§ª Phase 4: Testing & Launch (Month 3)

### Week 9-10: í†µí•© í…ŒìŠ¤íŠ¸

#### í…ŒìŠ¤íŠ¸ ê³„íš
```yaml
Unit Tests:
- API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- AI ëª¨ë¸ ì •í™•ë„ í…ŒìŠ¤íŠ¸
- ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

Integration Tests:
- End-to-end ì›Œí¬í”Œë¡œìš°
- ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
- ì—ëŸ¬ í•¸ë“¤ë§

Performance Tests:
- ë™ì‹œ ì‚¬ìš©ì 100ëª…
- ì‘ë‹µ ì‹œê°„ < 2ì´ˆ
- ì²˜ë¦¬ëŸ‰ 1000 req/min

Security Tests:
- API ì¸ì¦/ì¸ê°€
- SQL Injection
- XSS ë°©ì–´
```

#### í…ŒìŠ¤íŠ¸ ìë™í™”
```python
# tests/test_api.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_create_campaign():
    response = client.post(
        "/api/campaigns",
        json={
            "brand": "TestBrand",
            "keywords": ["keyword1", "keyword2"],
            "platforms": ["twitter", "instagram"]
        }
    )
    assert response.status_code == 200
    assert "campaign_id" in response.json()

def test_get_predictions():
    campaign_id = "test-campaign-123"
    response = client.get(f"/api/predictions/{campaign_id}")
    assert response.status_code == 200
    data = response.json()
    assert "predicted_purchase_intent" in data
    assert 0 <= data["confidence_score"] <= 100
```

### Week 11-12: ë² íƒ€ ëŸ°ì¹­

#### íŒŒì¼ëŸ¿ ê³ ê° ëª¨ì§‘
```yaml
ëŒ€ìƒ ê³ ê° (10ê°œ):
1. ëŒ€êµ¬ ì§€ì—­ ìŠ¤íƒ€íŠ¸ì—… 5ê°œ
2. ì¤‘ì†Œê¸°ì—… 3ê°œ
3. ë§ˆì¼€íŒ… ì—ì´ì „ì‹œ 2ê°œ

ì œê³µ í˜œíƒ:
- 3ê°œì›” ë¬´ë£Œ ì‚¬ìš©
- ì „ë‹´ ì§€ì›
- í”¼ë“œë°± ë°˜ì˜ ìš°ì„ ê¶Œ
- ì •ì‹ ëŸ°ì¹­ ì‹œ 50% í• ì¸

ìš”êµ¬ì‚¬í•­:
- ì£¼ 1íšŒ í”¼ë“œë°± ë¯¸íŒ…
- ì‚¬ìš© ë°ì´í„° ì œê³µ ë™ì˜
- ì‚¬ë¡€ ì—°êµ¬ ì°¸ì—¬
```

#### ëŸ°ì¹­ ì²´í¬ë¦¬ìŠ¤íŠ¸
```yaml
Technical:
â–¡ í”„ë¡œë•ì…˜ ì„œë²„ ì„¤ì •
â–¡ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
â–¡ ë°±ì—… ì‹œìŠ¤í…œ êµ¬ì¶•
â–¡ SSL ì¸ì¦ì„œ ì„¤ì¹˜
â–¡ CDN ì„¤ì •

Business:
â–¡ ì´ìš©ì•½ê´€ ì‘ì„±
â–¡ ê°œì¸ì •ë³´ì²˜ë¦¬ë°©ì¹¨
â–¡ ê°€ê²© ì •ì±… í™•ì •
â–¡ ê²°ì œ ì‹œìŠ¤í…œ í†µí•©
â–¡ ê³ ê° ì§€ì› ì±„ë„ ì˜¤í”ˆ

Marketing:
â–¡ ëœë”© í˜ì´ì§€ ì™„ì„±
â–¡ ì œí’ˆ ë°ëª¨ ë¹„ë””ì˜¤
â–¡ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ 5ê°œ
â–¡ í”„ë ˆìŠ¤ ë¦´ë¦¬ìŠ¤
â–¡ ì†Œì…œë¯¸ë””ì–´ ê³„ì •
```

## ğŸ“Š MVP Feature Set

### Core Features (í•„ìˆ˜)
```yaml
ë°ì´í„° ìˆ˜ì§‘:
âœ… Perigon API í†µí•©
âœ… 3ê°œ ì†Œì…œë¯¸ë””ì–´ í¬ë¡¤ë§
âœ… ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘

AI ë¶„ì„:
âœ… í•œêµ­ì–´ ê°ì„± ë¶„ì„
âœ… ì‹ ë¢°ë„ í‰ê°€
âœ… ê¸°ë³¸ ì˜ˆì¸¡ ëª¨ë¸

ëŒ€ì‹œë³´ë“œ:
âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
âœ… í•µì‹¬ ì§€í‘œ ì‹œê°í™”
âœ… ê¸°ë³¸ ë¦¬í¬íŒ…

API:
âœ… RESTful API
âœ… ì¸ì¦/ì¸ê°€
âœ… Rate limiting
```

### Nice-to-Have (ì„ íƒ)
```yaml
ê³ ê¸‰ ê¸°ëŠ¥:
âš ï¸ ë°ˆ ë¶„ì„ (Phase 2)
âš ï¸ ê²½ìŸì‚¬ ë¹„êµ (Phase 2)
âš ï¸ ì˜ˆì¸¡ ëª¨ë¸ ê³ ë„í™” (Phase 2)

í†µí•©:
âš ï¸ Slack ì•Œë¦¼ (Phase 2)
âš ï¸ Google Analytics (Phase 2)
âš ï¸ CRM ì—°ë™ (Phase 3)
```

## ğŸ’° MVP Budget

### ê°œë°œ ë¹„ìš© (3ê°œì›”)
```yaml
ì¸ê±´ë¹„:
- ê°œë°œì 3ëª… x â‚©8M x 3ê°œì›” = â‚©72M
- PM/ë””ìì´ë„ˆ 2ëª… x â‚©6M x 3ê°œì›” = â‚©36M
ì†Œê³„: â‚©108M

ì¸í”„ë¼:
- AWS: â‚©2M x 3ê°œì›” = â‚©6M
- API ë¹„ìš©: â‚©1M x 3ê°œì›” = â‚©3M
- ë„êµ¬/ë¼ì´ì„ ìŠ¤: â‚©3M
ì†Œê³„: â‚©12M

ë§ˆì¼€íŒ…:
- ì»¨í…ì¸  ì œì‘: â‚©5M
- ê´‘ê³ : â‚©10M
- ì´ë²¤íŠ¸: â‚©5M
ì†Œê³„: â‚©20M

ì´ ì˜ˆì‚°: â‚©140M
```

## ğŸ¯ ì‹ ìš©ë³´ì¦ê¸°ê¸ˆ ëŒ€íšŒ ì „ëµ

### ëŒ€íšŒ ì¤€ë¹„ (ë³‘í–‰)
```yaml
Week 1-4:
- ì‚¬ì—…ê³„íšì„œ ì‘ì„±
- íŒ€ êµ¬ì„± ì™„ë£Œ
- ì‹œì¥ ì¡°ì‚¬ ì™„ë£Œ

Week 5-8:
- MVP í”„ë¡œí† íƒ€ì… ê°œë°œ
- íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´
- ë°ëª¨ ì˜ìƒ ì œì‘

Week 9-12:
- ë°œí‘œ ìë£Œ ì¤€ë¹„
- í”¼ì¹­ ì—°ìŠµ
- ì‹¤ì œ ì‚¬ë¡€ í™•ë³´
```

### ì‹¬ì‚¬ ëŒ€ì‘ ì „ëµ
```yaml
ì°½ì˜ì„± (20ì ):
- "ì˜¨ë¼ì¸â‰ ì‹¤ì œ" ë…ì°½ì  ì ‘ê·¼
- ë°ˆ ë§ˆì¼€íŒ… ë¶„ì„ í˜ì‹ 

ê¸°ìˆ ì„± (20ì ):
- AI ëª¨ë¸ ì‹œì—°
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ë°ëª¨

ì‚¬ì—…ì„± (30ì ):
- íŒŒì¼ëŸ¿ ê³ ê° ì¦ì–¸
- ëª…í™•í•œ ìˆ˜ìµ ëª¨ë¸
- ROI ê³„ì‚° ì œì‹œ

ë³´ìœ ì—­ëŸ‰ (20ì ):
- íŒ€ ê²½ë ¥ ì†Œê°œ
- ê¸°ìˆ  ìŠ¤íƒ ì¦ëª…

ì§€ì—­ê¸°ì—¬ (10ì ):
- ëŒ€êµ¬ê²½ë¶ ê¸°ì—… ì§€ì›
- ì¼ìë¦¬ ì°½ì¶œ ê³„íš
```

## ğŸ“ˆ Post-MVP Roadmap

### Phase 2 (Month 4-6)
```yaml
ì œí’ˆ ê³ ë„í™”:
- ë°ˆ ë¶„ì„ ì—”ì§„
- ê³ ê¸‰ ì˜ˆì¸¡ ëª¨ë¸
- ëª¨ë°”ì¼ ì•±

ì‹œì¥ í™•ëŒ€:
- 100ê°œ ê³ ê° í™•ë³´
- Series A ì¤€ë¹„
- íŒŒíŠ¸ë„ˆì‹­ êµ¬ì¶•
```

### Phase 3 (Month 7-12)
```yaml
ìŠ¤ì¼€ì¼ì—…:
- ê¸€ë¡œë²Œ ì§„ì¶œ
- ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥
- AI ëª¨ë¸ íŠ¹í—ˆ
```

## âœ… Success Criteria

### MVP ì„±ê³µ ì§€í‘œ
```yaml
Technical:
â–¡ 99% Uptime
â–¡ <2ì´ˆ ì‘ë‹µ ì‹œê°„
â–¡ 70% ì˜ˆì¸¡ ì •í™•ë„

Business:
â–¡ 10ê°œ íŒŒì¼ëŸ¿ ê³ ê°
â–¡ NPS 40+
â–¡ 1ê°œ ìœ ë£Œ ì „í™˜

Competition:
â–¡ ì‹ ìš©ë³´ì¦ê¸°ê¸ˆ ëŒ€íšŒ ìˆ˜ìƒ
â–¡ ì–¸ë¡  ë³´ë„ 3ê±´+
â–¡ íˆ¬ì ê´€ì‹¬ í‘œëª… 2ê³³+
```

## ğŸš€ Launch Announcement

```markdown
# TrueVoice MVP ëŸ°ì¹­! ğŸ‰

ì‹œë„ëŸ¬ìš´ ì†Œìˆ˜ê°€ ì•„ë‹Œ, ì¡°ìš©í•œ ë‹¤ìˆ˜ì˜ ì§„ì§œ ëª©ì†Œë¦¬ë¥¼ ë“¤ì–´ë³´ì„¸ìš”.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
- ì‹¤ì‹œê°„ ì˜¨ë¼ì¸ ì—¬ë¡  ëª¨ë‹ˆí„°ë§
- AI ê¸°ë°˜ ì‹ ë¢°ë„ í‰ê°€
- ì‹¤ì œ ê³ ê° ë°˜ì‘ ì˜ˆì¸¡
- í•œêµ­ì–´ ë°ˆ/íŠ¸ë Œë“œ ë¶„ì„

## ğŸ’¡ íŠ¹ë³„ í˜œíƒ
- ë² íƒ€ ê¸°ê°„ 3ê°œì›” ë¬´ë£Œ
- ì „ë‹´ ì»¨ì„¤íŒ… ì œê³µ
- ì •ì‹ ëŸ°ì¹­ ì‹œ 50% í• ì¸

## ğŸš€ ì§€ê¸ˆ ì‹œì‘í•˜ê¸°
[app.truevoice.ai](https://app.truevoice.ai)

ë¬¸ì˜: hello@truevoice.ai
```

---

*MVP Roadmap v1.0*
*Last Updated: 2025ë…„ 1ì›”*
*TrueVoice Team*