# ë‹¤ì¤‘ í”Œë«í¼ í†µí•© ë°ì´í„° ìˆ˜ì§‘ ë° í‘œì‹œ ì „ëµ

**ì‘ì„±ì¼**: 2025-01-14
**ëª©ì **: ì»¤ë®¤ë‹ˆí‹°/ë‰´ìŠ¤/ìœ íŠœë¸Œ/ì¸ìŠ¤íƒ€ ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  í†µí•© í‘œì‹œí•˜ëŠ” êµ¬ì²´ì  ë°©ë²•ë¡ 
**ë¶„ì„ ë„êµ¬**: GPT API í™œìš© ì „ì œ

---

## ğŸ¯ í•µì‹¬ ë„ì „ê³¼ì œ ë¶„ì„

### í˜„ì‹¤ì  ì œì•½ì‚¬í•­ë“¤
```
ë°ì´í„° ìˆ˜ì§‘ í•œê³„:
âŒ í”Œë«í¼ë³„ ìƒì´í•œ API ì •ì±…
âŒ í¬ë¡¤ë§ ì°¨ë‹¨ ë° Rate limiting
âŒ ì‹¤ì‹œê°„ì„± vs ì•ˆì •ì„±ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„
âŒ ë°ì´í„° í’ˆì§ˆ í¸ì°¨ (ì •ì œ/ë¹„ì •ì œ)

í†µí•© í‘œì‹œ í•œê³„:
âŒ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° êµ¬ì¡° í†µì¼ì˜ ì–´ë ¤ì›€
âŒ í”Œë«í¼ë³„ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ì„¤ì • ë³µì¡ì„±
âŒ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì„±ëŠ¥ ë¬¸ì œ
âŒ ì‚¬ìš©ì ê²½í—˜ ì¼ê´€ì„± ìœ ì§€
```

### ì„±ê³µì„ ìœ„í•œ í•µì‹¬ ì „ëµ
```
âœ… ì ì§„ì  êµ¬ì¶•: í•µì‹¬ í”Œë«í¼ë¶€í„° ë‹¨ê³„ì  í™•ì¥
âœ… í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘: API + í¬ë¡¤ë§ + RSS ì¡°í•©
âœ… í†µí•© ë°ì´í„° ëª¨ë¸: í‘œì¤€í™”ëœ ë‚´ë¶€ ìŠ¤í‚¤ë§ˆ
âœ… ì§€ëŠ¥í˜• ìš°ì„ ìˆœìœ„: ì‹¤ì‹œê°„ì„±/ì¤‘ìš”ë„ ê¸°ë°˜ ì²˜ë¦¬
âœ… ì‚¬ìš©ì ë§ì¶¤í˜•: ê´€ì‹¬ì‚¬ ê¸°ë°˜ í•„í„°ë§
```

---

## ğŸ— í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì•„í‚¤í…ì²˜

### Phase 1: 3-Platform MVP (ê²€ì¦ëœ ì ‘ê·¼ë²•)
**ëª©í‘œ**: ì•ˆì •ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ê¸°ë°˜ êµ¬ì¶•

#### 1.1 ì»¤ë®¤ë‹ˆí‹° ë°ì´í„° (í´ë¦¬ì•™ ì¤‘ì‹¬)
```python
ì„ íƒ ì´ìœ : í¬ë¡¤ë§ ì¹œí™”ì , í’ˆì§ˆ ë†’ì€ í† ë¡ , RSS ì œê³µ

ìˆ˜ì§‘ ì „ëµ:
- í´ë¦¬ì•™ RSS í”¼ë“œ (ì‹¤ì‹œê°„ ê¸°ë°˜)
- ëª¨ë°”ì¼ API ì—­ë¶„ì„ (ìƒì„¸ ë°ì´í„°)
- 10ë¶„ ê°„ê²© í¬ë¡¤ë§ (ëŒ“ê¸€/ì¶”ì²œìˆ˜)

ê¸°ìˆ  ìŠ¤íƒ:
import feedparser
import requests
from bs4 import BeautifulSoup
import asyncio

# RSS + API í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘ê¸°
class ClienCollector:
    def __init__(self):
        self.rss_url = "https://www.clien.net/service/rss/allrecentnews"
        self.api_base = "https://m.clien.net/service"
    
    async def collect_realtime(self):
        # RSSë¡œ ìµœì‹  ê¸€ ê°ì§€
        feed = feedparser.parse(self.rss_url)
        
        # ê° ê¸€ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        for entry in feed.entries:
            post_id = extract_post_id(entry.link)
            detail = await self.get_post_detail(post_id)
            yield self.normalize_data(detail)
```

#### 1.2 ë‰´ìŠ¤ ë°ì´í„° (RSS ì¤‘ì‹¬)
```python
ì„ íƒ ì´ìœ : ì‹¤ì‹œê°„ì„± í™•ë³´, ì•ˆì •ì  ìˆ˜ì§‘, ë¬´ë£Œ

ìˆ˜ì§‘ ì „ëµ:
- ì£¼ìš” ì–¸ë¡ ì‚¬ RSS í”¼ë“œ (20ê°œì‚¬)
- 1ë¶„ ê°„ê²© ì²´í¬, ì¦‰ì‹œ ì²˜ë¦¬
- GPT APIë¡œ ì •ì¹˜ì  ì„±í–¥ ìë™ ë¶„ë¥˜

RSS í”¼ë“œ ë§¤ë‹ˆì €:
class NewsRSSCollector:
    def __init__(self):
        self.feeds = {
            'progressive': [
                'http://www.hani.co.kr/rss/',
                'https://rss.khan.co.kr/kh_politics.xml'
            ],
            'conservative': [
                'https://rss.chosun.com/rss/politics.xml',
                'https://rss.donga.com/politics.xml'
            ],
            'moderate': [
                'https://rss.ytn.co.kr/ytn_man_news_rss.xml'
            ]
        }
    
    async def collect_all_sources(self):
        for category, urls in self.feeds.items():
            for url in urls:
                articles = await self.parse_rss(url)
                for article in articles:
                    # GPT APIë¡œ ì¶”ê°€ ë¶„ì„
                    analysis = await self.analyze_with_gpt(article)
                    yield self.create_unified_format(article, analysis, category)
```

#### 1.3 ìœ íŠœë¸Œ ë°ì´í„° (API + ì„ ë³„ì  í¬ë¡¤ë§)
```python
ì„ íƒ ì´ìœ : ì˜í–¥ë ¥ ë†’ìŒ, API ì•ˆì •ì„±, ëŒ“ê¸€ ì ‘ê·¼ì„±

ìˆ˜ì§‘ ì „ëµ:
- YouTube Data API v3 (ì¼ì¼ í• ë‹¹ëŸ‰ ë‚´)
- ì •ì¹˜ ì±„ë„ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ íƒ€ê²ŸíŒ… (30ê°œ ì±„ë„)
- ì£¼ìš” ì˜ìƒì˜ ëŒ“ê¸€ë§Œ ì„ ë³„ ìˆ˜ì§‘

íš¨ìœ¨ì  API ì‚¬ìš©:
class YouTubeCollector:
    def __init__(self):
        self.api_key = os.getenv('YOUTUBE_API_KEY')
        self.target_channels = [
            'UC-6rZfTd3YODLWzAPrwPWDQ',  # ê°€ë¡œì„¸ë¡œì—°êµ¬ì†Œ
            'UCfk8ddtxrD3n6O2VmbQM0PA',  # ì´ìŠˆì™•
            # ... ì£¼ìš” ì •ì¹˜ ì±„ë„ë“¤
        ]
        self.daily_quota_used = 0
        self.quota_limit = 9000  # ì—¬ìœ ë¶„ 1000 units
    
    async def collect_smart(self):
        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìˆ˜ì§‘
        for channel_id in self.target_channels:
            if self.daily_quota_used > self.quota_limit:
                break
                
            # ìµœê·¼ 3ì¼ ì˜ìƒë§Œ (í• ë‹¹ëŸ‰ ì ˆì•½)
            videos = await self.get_recent_videos(channel_id, max_results=10)
            
            for video in videos:
                # ì¡°íšŒìˆ˜ ê¸°ë°˜ í•„í„°ë§ (10ë§Œ ì´ìƒë§Œ)
                if video['viewCount'] > 100000:
                    comments = await self.get_top_comments(video['id'], max_results=50)
                    yield self.format_video_data(video, comments)
```

### Phase 2: í™•ì¥ í”Œë«í¼ (ì•ˆì •í™” í›„)
#### ì¸ìŠ¤íƒ€ê·¸ë¨, íŠ¸ìœ„í„°, ì¶”ê°€ ì»¤ë®¤ë‹ˆí‹° ë‹¨ê³„ì  ì¶”ê°€

---

## ğŸ”§ í†µí•© ë°ì´í„° ëª¨ë¸ ì„¤ê³„

### í‘œì¤€í™”ëœ í†µí•© ìŠ¤í‚¤ë§ˆ
```python
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

class Platform(Enum):
    CLIEN = "clien"
    NEWS_RSS = "news_rss"
    YOUTUBE = "youtube"
    INSTAGRAM = "instagram"

class ContentType(Enum):
    POST = "post"
    COMMENT = "comment"
    VIDEO = "video"
    NEWS = "news"

@dataclass
class UnifiedContent:
    # ê³µí†µ ë©”íƒ€ë°ì´í„°
    id: str
    platform: Platform
    content_type: ContentType
    title: str
    content: str
    author: str  # ìµëª…í™”ëœ ID
    created_at: datetime
    url: str
    
    # ì°¸ì—¬ ì§€í‘œ
    views: int = 0
    likes: int = 0
    dislikes: int = 0
    comments_count: int = 0
    shares: int = 0
    
    # ë¶„ì„ ê²°ê³¼ (GPT API)
    sentiment_score: float = 0.0  # -1 to 1
    emotion_tags: list[str] = None
    keywords: list[str] = None
    political_leaning: str = "neutral"  # progressive/conservative/neutral
    
    # í”Œë«í¼ë³„ íŠ¹ìˆ˜ ë°ì´í„°
    platform_specific: dict = None

# ì‚¬ìš© ì˜ˆì‹œ
def normalize_clien_post(raw_data) -> UnifiedContent:
    return UnifiedContent(
        id=f"clien_{raw_data['id']}",
        platform=Platform.CLIEN,
        content_type=ContentType.POST,
        title=raw_data['title'],
        content=raw_data['content'],
        author=hash_user_id(raw_data['author']),
        created_at=parse_datetime(raw_data['created']),
        url=raw_data['url'],
        views=raw_data.get('views', 0),
        likes=raw_data.get('likes', 0),
        comments_count=raw_data.get('comment_count', 0),
        platform_specific={'board': raw_data['board']}
    )
```

---

## ğŸš€ ì‹¤ì‹œê°„ í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### ì´ë²¤íŠ¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì•„í‚¤í…ì²˜
```python
import asyncio
from kafka import KafkaProducer, KafkaConsumer
import redis
import json

class RealTimeDataHub:
    def __init__(self):
        self.kafka_producer = KafkaProducer(
            bootstrap_servers=['localhost:9092'],
            value_serializer=lambda x: json.dumps(x).encode('utf-8')
        )
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.gpt_analyzer = GPTAnalyzer()
    
    async def process_unified_content(self, content: UnifiedContent):
        # 1. GPT API ë¶„ì„
        analysis = await self.gpt_analyzer.analyze(content)
        content.sentiment_score = analysis['sentiment']
        content.emotion_tags = analysis['emotions']
        content.keywords = analysis['keywords']
        
        # 2. ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ë°œì†¡
        self.kafka_producer.send('unified_content', content.__dict__)
        
        # 3. ìºì‹œ ì—…ë°ì´íŠ¸
        await self.update_realtime_cache(content)
        
        # 4. íŠ¸ë Œë”© ì—…ë°ì´íŠ¸
        await self.update_trending_metrics(content)

class GPTAnalyzer:
    def __init__(self):
        self.client = openai.AsyncOpenAI()
        self.cache = {}  # ë™ì¼ í…ìŠ¤íŠ¸ ì¬ë¶„ì„ ë°©ì§€
    
    async def analyze(self, content: UnifiedContent) -> dict:
        cache_key = hashlib.md5(content.content.encode()).hexdigest()
        
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ì œëª©: {content.title}
        ë‚´ìš©: {content.content}
        í”Œë«í¼: {content.platform.value}
        
        ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜:
        {{
            "sentiment": -1~1 ì‚¬ì´ ìˆ˜ì¹˜,
            "emotions": ["ë¶„ë…¸", "ê¸°ëŒ€", "ë¶ˆì•ˆ"] ì¤‘ í•´ë‹¹í•˜ëŠ” ê²ƒë“¤,
            "keywords": í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ,
            "political_leaning": "progressive/conservative/neutral",
            "controversy_level": 0~10 ë…¼ë€ ì •ë„
        }}
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        
        result = json.loads(response.choices[0].message.content)
        self.cache[cache_key] = result
        return result
```

---

## ğŸ“Š í†µí•© í‘œì‹œ ì „ëµ

### 1. ì‹œê°„ì¶• ê¸°ë°˜ í†µí•© íƒ€ì„ë¼ì¸
```javascript
// React ì»´í¬ë„ŒíŠ¸ ì˜ˆì‹œ
const UnifiedTimeline = () => {
    const [timelineData, setTimelineData] = useState([]);
    const [filters, setFilters] = useState({
        platforms: ['all'],
        sentiment: 'all',
        timeRange: '24h'
    });

    // WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    useEffect(() => {
        const ws = new WebSocket('ws://localhost:8000/ws/timeline');
        
        ws.onmessage = (event) => {
            const newContent = JSON.parse(event.data);
            setTimelineData(prev => [newContent, ...prev].slice(0, 100));
        };
        
        return () => ws.close();
    }, []);

    return (
        <div className="unified-timeline">
            {timelineData.map(item => (
                <TimelineItem 
                    key={item.id}
                    content={item}
                    platform={item.platform}
                />
            ))}
        </div>
    );
};

const TimelineItem = ({ content, platform }) => {
    const getPlatformIcon = (platform) => {
        const icons = {
            'clien': 'ğŸ’¬',
            'news_rss': 'ğŸ“°', 
            'youtube': 'ğŸ“º',
            'instagram': 'ğŸ“¸'
        };
        return icons[platform] || 'ğŸ“„';
    };

    return (
        <div className={`timeline-item ${platform}`}>
            <div className="platform-indicator">
                {getPlatformIcon(platform)}
            </div>
            <div className="content-preview">
                <h4>{content.title}</h4>
                <p>{content.content.slice(0, 100)}...</p>
                <div className="metrics">
                    <span>ğŸ‘€ {content.views}</span>
                    <span>ğŸ‘ {content.likes}</span>
                    <span>ğŸ’¬ {content.comments_count}</span>
                    <SentimentBadge score={content.sentiment_score} />
                </div>
            </div>
        </div>
    );
};
```

### 2. í”Œë«í¼ë³„ í´ëŸ¬ìŠ¤í„° ë·°
```javascript
const PlatformClusterView = () => {
    return (
        <div className="platform-clusters">
            <div className="cluster community">
                <h3>ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘</h3>
                <ClienPosts />
                <RedditPosts />
            </div>
            
            <div className="cluster media">
                <h3>ë¯¸ë””ì–´ ë³´ë„</h3>
                <NewsArticles />
            </div>
            
            <div className="cluster social">
                <h3>ì†Œì…œ í™•ì‚°</h3>
                <YouTubeVideos />
                <InstagramPosts />
            </div>
        </div>
    );
};
```

### 3. ì´ìŠˆë³„ í¬ë¡œìŠ¤ í”Œë«í¼ ë¶„ì„
```javascript
const CrossPlatformAnalysis = ({ keyword }) => {
    const [analysis, setAnalysis] = useState(null);
    
    useEffect(() => {
        // í‚¤ì›Œë“œë³„ í”Œë«í¼ ê°„ ë°ì´í„° ë¶„ì„
        fetchCrossPlatformData(keyword).then(setAnalysis);
    }, [keyword]);

    if (!analysis) return <LoadingSpinner />;

    return (
        <div className="cross-platform-analysis">
            <div className="sentiment-comparison">
                <h4>í”Œë«í¼ë³„ ê°ì„± ë¶„í¬</h4>
                <BarChart data={analysis.sentiment_by_platform} />
            </div>
            
            <div className="influence-flow">
                <h4>ì˜í–¥ë ¥ í™•ì‚° ê²½ë¡œ</h4>
                <SankeyDiagram data={analysis.influence_flow} />
            </div>
            
            <div className="timeline-correlation">
                <h4>ì‹œê°„ëŒ€ë³„ ë°˜ì‘ íŒ¨í„´</h4>
                <LineChart data={analysis.timeline_data} />
            </div>
        </div>
    );
};
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ
```python
class SmartCache:
    def __init__(self):
        self.redis = redis.Redis()
        self.cache_rules = {
            'trending': 60,      # 1ë¶„
            'analysis': 300,     # 5ë¶„  
            'timeline': 30,      # 30ì´ˆ
            'static': 3600       # 1ì‹œê°„
        }
    
    async def get_or_compute(self, key, compute_func, cache_type='analysis'):
        cached = self.redis.get(key)
        if cached:
            return json.loads(cached)
        
        result = await compute_func()
        ttl = self.cache_rules[cache_type]
        self.redis.setex(key, ttl, json.dumps(result))
        return result
```

### 2. ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì²˜ë¦¬
```python
from heapq import heappush, heappop

class PriorityProcessor:
    def __init__(self):
        self.queue = []
        self.priorities = {
            'breaking_news': 1,
            'viral_content': 2,
            'regular_content': 3
        }
    
    def add_content(self, content, priority_type='regular_content'):
        priority = self.priorities[priority_type]
        heappush(self.queue, (priority, content.created_at, content))
    
    async def process_next(self):
        if self.queue:
            _, _, content = heappop(self.queue)
            return await self.process_content(content)
```

---

## ğŸ¯ ì‹¤í˜„ ê°€ëŠ¥í•œ ë‹¨ê³„ë³„ ë¡œë“œë§µ

### Phase 1: 3-Platform MVP (2-3ê°œì›”)
```
Week 1-2: í†µí•© ë°ì´í„° ëª¨ë¸ ì„¤ê³„
Week 3-4: í´ë¦¬ì•™ ìˆ˜ì§‘ê¸° êµ¬í˜„
Week 5-6: ë‰´ìŠ¤ RSS ìˆ˜ì§‘ê¸° êµ¬í˜„  
Week 7-8: ìœ íŠœë¸Œ ìˆ˜ì§‘ê¸° êµ¬í˜„
Week 9-10: GPT API ë¶„ì„ íŒŒì´í”„ë¼ì¸
Week 11-12: ê¸°ë³¸ í†µí•© UI êµ¬í˜„
```

### Phase 2: ì•ˆì •í™” ë° ìµœì í™” (1-2ê°œì›”)
```
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”
- ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
- ë°ì´í„° í’ˆì§ˆ ê°œì„ 
- ì¶”ê°€ ì‹œê°í™” êµ¬í˜„
```

### Phase 3: í”Œë«í¼ í™•ì¥ (2-3ê°œì›”)
```
- ì¸ìŠ¤íƒ€ê·¸ë¨ ì¶”ê°€
- íŠ¸ìœ„í„° ì¶”ê°€
- ì¶”ê°€ ì»¤ë®¤ë‹ˆí‹° í™•ì¥
- ê³ ë„í™”ëœ ë¶„ì„ ê¸°ëŠ¥
```

---

## ğŸ’¡ í•µì‹¬ ì„±ê³µ ìš”ì¸

### 1. ì ì§„ì  êµ¬ì¶•
**ì™„ë²½í•œ ê²ƒì„ í•œë²ˆì— ë§Œë“¤ë ¤ í•˜ì§€ ë§ê³ , ì‘ë™í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘**

### 2. ë°ì´í„° í’ˆì§ˆ ìš°ì„ 
**ë§ì€ ë°ì´í„°ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°**

### 3. ì‚¬ìš©ì ì¤‘ì‹¬ ì„¤ê³„
**ê°œë°œìê°€ ë³´ê³  ì‹¶ì€ ê²ƒì´ ì•„ë‹ˆë¼ ì‚¬ìš©ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê²ƒ**

### 4. ê¸°ìˆ  í˜„ì‹¤ì„±
**ì´ìƒì ì¸ ê¸°ìˆ ë³´ë‹¤ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê¸°ìˆ **

---

## ğŸ“‹ ìµœì¢… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
âœ… í†µí•© ë°ì´í„° ëª¨ë¸ ì™„ì„±
âœ… 3ê°œ í”Œë«í¼ ì•ˆì •ì  ìˆ˜ì§‘
âœ… GPT API ë¶„ì„ íŒŒì´í”„ë¼ì¸  
âœ… ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
âœ… ê¸°ë³¸ í†µí•© UI êµ¬í˜„
âœ… ìºì‹± ë° ì„±ëŠ¥ ìµœì í™”
âœ… ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ë° í”¼ë“œë°±
```

**í•µì‹¬: í™”ë ¤í•œ ê¸°ëŠ¥ë³´ë‹¤ ì•ˆì •ì ì´ê³  ìœ ìš©í•œ ì„œë¹„ìŠ¤**

---

*"ë‹¤ì–‘í•œ í”Œë«í¼ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ë³´ëŠ” ê²ƒ, ê·¸ê²ƒì´ ì§„ì •í•œ í†µì°°ì˜ ì‹œì‘ì´ë‹¤."*